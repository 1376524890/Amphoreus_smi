# 翁法罗斯模拟仿真项目 
## BringStorm
* 创建11个Agent，其中11个Agent模拟11个性格各异的人类英雄，其个性设定参考 AMPHOREUS/《崩坏：星穹铁道》命途智能体个性设定.md，1个大Agent模拟系统管理员。
* 使用系统prompt的方式给不同Agent设置各自的身份，其中9个Agent的系统提示词固定不变，1个Agent的系统提示词根据上一次迭代结果进行优化更新，管理员Agent的提示词在每次迭代后询问用户是否需要更新，如需更新由用户自行设定
* 搜集并制作可以被所有Agent只读访问的背景知识库作为世界观背景
* 在每次迭代中记录所有agent的输出保存为json文件作为运行日志，Agent的每个动作需参考日志和世界观背景
* 管理员Agent在每一次迭代结束后筛选日志中有利于收敛的条目并将其写入另一个json文件中作为世界观补充
* Agent的每个动作均被写入日志文件中，每轮动作结束后由管理员agent根据日志评价各个agent的奖励参数，并根据目标有无达成决定是否推进时间阶段
* 如连续多轮迭代智能体行为日志差别较小则判定收敛，迭代结束


## 技术实现
1. 使用LangChain作为框架控制多agent调用

# 翁法罗斯模拟仿真项目技术方案

## 项目架构概述graph TD
    A[用户界面] --> B[管理员Agent]
    B --> C[泰坦Agent 1-12]
    C --> D[知识库系统]
    B --> E[日志系统]
    E --> F[收敛检测器]
    F --> G[知识库更新]
    G --> D

需要优化的关键环节
(1) 奖励函数设计

- 问题：当前仅提到"评价各个agent的奖励参数"，缺乏具体量化指标
- 优化：建立多维奖励体系，平衡命途特性与全局目标

优化方案设计：
奖励函数：多维度评估指标
- 命途契合度（行为符合其哲学设定）
- 阶段目标达成度
结合以上两点内容由系统agent参照行为日志进行评价

(2) 收敛检测机制

- 问题：仅通过"连续多轮迭代智能体行为日志差别较小"判断，可能不准确
- 优化：引入行为相似度算法（如余弦相似度）+ 奖励稳定性分析
(3) 世界观动态更新

- 问题：未明确日志条目如何转化为世界观知识
由系统agent总结上一轮动作中会对虚拟世界产生影响的行为并添加到世界观记录中
- 优化：设计知识抽取规则，建立关联图谱存储世界观实体关系
(4) Agent协作机制

- 问题：多个Agent间的交互规则不明确
- agent发出动作并由系统agent结合虚拟世界当前情况进行分析总结，并根据影响结果修改其他agent的状态

wengfalos/
 ├─ main.py                 # 启动入口
 ├─ config.py               # 全局配置（API Key、超参数）
 ├─ world/
 │   ├─ world.json          # 原始世界观（文件2）
 │   └─ world_kb.json       # 运行时知识库（自动生成）
 ├─ agents/
 │   ├─ agent_templates.py  # 11 套系统提示词
 │   └─ agent.py            # Agent 类
 ├─ llm/
 │   └─ qwen_plus.py        # 阿里云百炼封装
 ├─ log/
 │   ├─ run_*.json          # 每轮完整日志
 │   └─ summary.json        # 管理员筛选后的补充知识
 └─ utils/
     ├─ similarity.py       # 余弦相似度收敛检测
     └─ reward.py           # 奖励计算